{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from medicalDataLoad import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. load入院数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56416, 33)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#829177\n",
    "diaPath = \"hospitalData/df_hospital_20171219_diseasematchKeywordNum.csv\"\n",
    "pd_dia = pd.read_csv(diaPath,  encoding='utf8').drop_duplicates()\n",
    "pd_dia.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'4': '精神和行为障碍', '0': '某些传染病和寄生虫病', '2': '血液及造血器官疾病和某些涉及免疫机制的疾患', '13': '泌尿生殖系统疾病', '7': '耳和乳突疾病', '3': '内分泌、营养和代谢疾病', '15': '起源于围生期的某些情况', '11': '皮肤和皮下组织病', '14': '妊娠分娩及产褥期', '9': '呼吸系统疾病', '20': '影响健康状态和保健机构接触的因素', '6': '眼和附器疾病', '5': '神经系统疾病', '1': '肿瘤', '12': '肌肉和骨骼系统和结缔组织疾病', '10': '消化系统疾病', '17': '症状、体症和临床与实验室异常所见，不可归类在他处者', '18': '损伤、中毒和外因的某些其它后果', '19': '疾病和死亡的外因', '8': '循环系统疾病', '16': '先天畸形、变性和染色体异常'}\n"
     ]
    }
   ],
   "source": [
    "def loadCodeType(fileName):\n",
    "    fileList = list(open(fileName,\"r\").readlines())\n",
    "    #print(fileList)\n",
    "    firstCode2IndexDict = dict()\n",
    "    firstIndex2TypeDict = dict()\n",
    "    for i in range(len(fileList)):\n",
    "        itemArr = fileList[i].strip().split(\" \")\n",
    "        firstCode2IndexDict[itemArr[0]] = itemArr[1]\n",
    "        firstIndex2TypeDict[itemArr[1]] = itemArr[2]\n",
    "    return firstCode2IndexDict, firstIndex2TypeDict\n",
    "fileName = \"datasets/firstCode2Index2Type.txt\"\n",
    "firstCode2IndexDict, firstIndex2TypeDict = loadCodeType(fileName)\n",
    "#print(firstCode2IndexDict)\n",
    "print(firstIndex2TypeDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.选取使用的字段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FirstCode</th>\n",
       "      <th>disease</th>\n",
       "      <th>chief_complaintKey</th>\n",
       "      <th>present_illnessKey</th>\n",
       "      <th>admission_situationKey</th>\n",
       "      <th>treat_processKey</th>\n",
       "      <th>discharge_situationKey</th>\n",
       "      <th>discharge_orderKey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I00-I99</td>\n",
       "      <td>脑梗死</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>侧肢体无力 双侧 病理征 患者病情 伸舌居中 肌力肌张力 心慌胸闷 无恶心呕吐 查房 肢体抽...</td>\n",
       "      <td>侧肢体无力 双侧 病理征 患者病情 伸舌居中 肌力肌张力 心慌胸闷 无恶心呕吐 查房 肢体抽...</td>\n",
       "      <td>侧肢体无力 双侧 病理征 患者病情 伸舌居中 肌力肌张力 心慌胸闷 无恶心呕吐 查房 肢体抽...</td>\n",
       "      <td>侧肢体无力 双侧 病理征 患者病情 伸舌居中 肌力肌张力 心慌胸闷 无恶心呕吐 查房 肢体抽...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I00-I99</td>\n",
       "      <td>脑梗死</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>左侧 未见异常 切题 腱反射 病理反射阴性 右侧顶叶 CT 记忆力下降 伸舌 轮替动作 肢体...</td>\n",
       "      <td>脑梗死</td>\n",
       "      <td>入院 脑萎缩 血管动脉硬化 双侧脑室 空蝶鞍 化验结果 桥脑 大脑后动脉狭窄 放射冠区 对症...</td>\n",
       "      <td>脑梗死 脑萎缩 双膝 3. 脑动脉硬化 退行性骨关节炎 狭窄</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I00-I99</td>\n",
       "      <td>脑梗死</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>双侧 查房 双侧瞳孔 浅感觉 无恶心呕吐 心律齐 伸舌居中 双肺呼吸音清 巴氏征阴性 等大 ...</td>\n",
       "      <td>双侧 查房 双侧瞳孔 浅感觉 无恶心呕吐 心律齐 伸舌居中 双肺呼吸音清 巴氏征阴性 等大 ...</td>\n",
       "      <td>双侧 查房 双侧瞳孔 浅感觉 无恶心呕吐 心律齐 伸舌居中 双肺呼吸音清 巴氏征阴性 等大 ...</td>\n",
       "      <td>双侧 查房 双侧瞳孔 浅感觉 无恶心呕吐 心律齐 伸舌居中 双肺呼吸音清 巴氏征阴性 等大 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FirstCode disease chief_complaintKey present_illnessKey  \\\n",
       "0   I00-I99     脑梗死                NaN                NaN   \n",
       "1   I00-I99     脑梗死                NaN                NaN   \n",
       "2   I00-I99     脑梗死                NaN                NaN   \n",
       "\n",
       "                              admission_situationKey  \\\n",
       "0  侧肢体无力 双侧 病理征 患者病情 伸舌居中 肌力肌张力 心慌胸闷 无恶心呕吐 查房 肢体抽...   \n",
       "1  左侧 未见异常 切题 腱反射 病理反射阴性 右侧顶叶 CT 记忆力下降 伸舌 轮替动作 肢体...   \n",
       "2  双侧 查房 双侧瞳孔 浅感觉 无恶心呕吐 心律齐 伸舌居中 双肺呼吸音清 巴氏征阴性 等大 ...   \n",
       "\n",
       "                                    treat_processKey  \\\n",
       "0  侧肢体无力 双侧 病理征 患者病情 伸舌居中 肌力肌张力 心慌胸闷 无恶心呕吐 查房 肢体抽...   \n",
       "1                                               脑梗死    \n",
       "2  双侧 查房 双侧瞳孔 浅感觉 无恶心呕吐 心律齐 伸舌居中 双肺呼吸音清 巴氏征阴性 等大 ...   \n",
       "\n",
       "                              discharge_situationKey  \\\n",
       "0  侧肢体无力 双侧 病理征 患者病情 伸舌居中 肌力肌张力 心慌胸闷 无恶心呕吐 查房 肢体抽...   \n",
       "1  入院 脑萎缩 血管动脉硬化 双侧脑室 空蝶鞍 化验结果 桥脑 大脑后动脉狭窄 放射冠区 对症...   \n",
       "2  双侧 查房 双侧瞳孔 浅感觉 无恶心呕吐 心律齐 伸舌居中 双肺呼吸音清 巴氏征阴性 等大 ...   \n",
       "\n",
       "                                  discharge_orderKey  \n",
       "0  侧肢体无力 双侧 病理征 患者病情 伸舌居中 肌力肌张力 心慌胸闷 无恶心呕吐 查房 肢体抽...  \n",
       "1                    脑梗死 脑萎缩 双膝 3. 脑动脉硬化 退行性骨关节炎 狭窄   \n",
       "2  双侧 查房 双侧瞳孔 浅感觉 无恶心呕吐 心律齐 伸舌居中 双肺呼吸音清 巴氏征阴性 等大 ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_dia_dis = pd_dia[[\"FirstCode\",\"disease\",\"chief_complaintKey\",\"present_illnessKey\",\"admission_situationKey\",\"treat_processKey\",\n",
    "                     \"discharge_situationKey\",\"discharge_orderKey\"]]\n",
    "pd_dia_dis.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### list按比例随机切分 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#随机按照指定的比例切分训练集合和测试集合\n",
    "def doDatasetSplit(x,x_admin, y, test_size):\n",
    "    X_num=len(x)\n",
    "    train_index=[ i for i in range(X_num)]\n",
    "    #print(train_index)\n",
    "    test_index=[]\n",
    "    test_num=int(X_num*test_size)\n",
    "    #print(\"test=\",test_num)\n",
    "    #随机选取index\n",
    "    for i in range(test_num):\n",
    "        randomIndex=int(np.random.uniform(0,len(train_index)))\n",
    "        if randomIndex not in train_index:\n",
    "            continue\n",
    "        test_index.append(train_index[randomIndex])\n",
    "        #print(randomIndex)\n",
    "        train_index.remove(randomIndex)\n",
    "    #train,test的index是抽取的数据集X的序号\n",
    "    x_disease_train = [x[item] for item in train_index]\n",
    "    x_admin_train = [x_admin[item] for item in train_index]\n",
    "    x_disease_test = [x[item] for item in test_index]\n",
    "    x_admin_test = [x_admin[item] for item in test_index]\n",
    "    \n",
    "    y_train = [y[item] for item in train_index]\n",
    "    y_test = [y[item] for item in test_index]\n",
    "\n",
    "    return x_disease_train, x_admin_train, x_disease_test,x_admin_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.全量数据集合切分成训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size= 46291 test size= 10125\n",
      "sum= 56416\n"
     ]
    }
   ],
   "source": [
    "#1.load all datasets  2.do split on each first type datasets 3.merge to a final train and test sets 4.word to vector 5.do rf train and test\n",
    "#1.load all dataset pd_dia_dis\n",
    "def classifyDatasetsTF(pd_dia_dis,columnName, rate):\n",
    "    x_disease_trainAll = list()\n",
    "    x_admin_trainAll = list()\n",
    "    x_disease_testAll = list()\n",
    "    x_admin_testAll = list()\n",
    "    y_trainAll = list()\n",
    "    y_testAll = list()\n",
    "    \n",
    "    for item in firstCode2IndexDict.keys():\n",
    "        #2.do split oon each first type, disease and admission_situation\n",
    "        #print(\"item=\", item,firstCode2IndexDict[item])\n",
    "        pd_tmp = pd_dia_dis[pd_dia_dis[\"FirstCode\"]==item]\n",
    "        x_disease = pd_tmp['disease'].tolist()\n",
    "        #print(\"dis num=\",len(x_disease))\n",
    "        x_admin = pd_tmp[columnName].tolist()\n",
    "\n",
    "        #x_admin = pd_tmp[\"admission_situationKey\"].tolist()\n",
    "        label = firstCode2IndexDict[item]\n",
    "        nums = len(x_disease)\n",
    "        if nums==0:\n",
    "            continue\n",
    "        y = [label]*nums\n",
    "        x_disease_train, x_admin_train, x_disease_test,x_admin_test, y_train, y_test = doDatasetSplit(x_disease,x_admin, y, rate)\n",
    "        #3.merge \n",
    "        x_disease_trainAll.extend(x_disease_train)\n",
    "        x_admin_trainAll.extend(x_admin_train)\n",
    "        x_disease_testAll.extend(x_disease_test)\n",
    "        x_admin_testAll.extend(x_admin_test)\n",
    "        y_trainAll.extend(y_train)\n",
    "        y_testAll.extend(y_test)\n",
    "    print(\"train size=\", len(y_trainAll), \"test size=\", len(y_testAll))\n",
    "    print(\"sum=\",len(y_trainAll)+len(y_testAll))\n",
    "        \n",
    "    return x_disease_trainAll, x_admin_trainAll,x_disease_testAll,x_admin_testAll, y_trainAll, y_testAll\n",
    "rate = 0.2\n",
    "columnName = \"admission_situationKey\"\n",
    "x_disease_trainAll, x_admin_trainAll,x_disease_testAll,x_admin_testAll, y_trainAll, y_testAll = classifyDatasetsTF(pd_dia_dis,columnName,rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def doPrepareCNN(x_disease_trainAll, x_admin_trainAll, y_trainAll, filePath):\n",
    "    f = open(filePath+\".feature\", \"w\")\n",
    "    f_label =open(filePath+\".label\" ,\"w\")\n",
    "    for i in range (len(x_disease_trainAll)):\n",
    "        dis = x_disease_trainAll[i]\n",
    "        adm = x_admin_trainAll[i]\n",
    "       \n",
    "        y_train = y_trainAll[i]\n",
    "        \n",
    "        y_trainStr = (\"%s \" %(y_train))\n",
    "        #featureStr = (\"%s%s\" %(str(dis)+\" \" + str(adm) + \" __label__\", y_trainStr))\n",
    "                               \n",
    "        featureStr = (\"%s\" %(str(dis)+\" \" + str(adm)))\n",
    "        labelStr = (\"%s\" %(y_trainStr))\n",
    "        f.write(str(featureStr)+\"\\n\")\n",
    "        f_label.write(labelStr+\"\\n\")\n",
    "    f.flush()\n",
    "    f.close()\n",
    "\n",
    "filePath = \"cnnModel/datasets/train1\"\n",
    "doPrepareCNN(x_disease_trainAll, x_admin_trainAll, y_trainAll, filePath )\n",
    "filePathtest = \"cnnModel/datasets/test1\"\n",
    "doPrepareCNN(x_disease_testAll,x_admin_testAll,y_testAll, filePathtest )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size= 46282 test size= 10134\n",
      "sum= 56416\n"
     ]
    }
   ],
   "source": [
    "rate = 0.2\n",
    "columnName = \"discharge_situationKey\"\n",
    "x_disease_trainAll, x_dissituation_trainAll,x_disease_testAll,x_dissituation_testAll, y_trainAll, y_testAll = classifyDatasetsTF(pd_dia_dis,columnName,rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size= 46240 test size= 10176\n",
      "sum= 56416\n",
      "train size= 46251 test size= 10165\n",
      "sum= 56416\n"
     ]
    }
   ],
   "source": [
    "rate = 0.2\n",
    "columnName = \"treat_processKey\"\n",
    "x_disease_trainAll, x_treat_trainAll,x_disease_testAll,x_treat_testAll, y_trainAll, y_testAll = classifyDatasetsTF(pd_dia_dis,columnName,rate)\n",
    "rate = 0.2\n",
    "columnName = \"discharge_orderKey\"\n",
    "x_disease_trainAll, x_disorder_trainAll,x_disease_testAll,x_disorder_testAll, y_trainAll, y_testAll = classifyDatasetsTF(pd_dia_dis,columnName,rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#随机按照指定的比例切分训练集合和测试集合\n",
    "def doDatasetSplitAll(x,x_admin,x_dissituation,x_treat,x_disorder,y, test_size):\n",
    "    X_num=len(x)\n",
    "    train_index=[ i for i in range(X_num)]\n",
    "    #print(train_index)\n",
    "    test_index=[]\n",
    "    test_num=int(X_num*test_size)\n",
    "    #print(\"test=\",test_num)\n",
    "    #随机选取index\n",
    "    for i in range(test_num):\n",
    "        randomIndex=int(np.random.uniform(0,len(train_index)))\n",
    "        if randomIndex not in train_index:\n",
    "            continue\n",
    "        test_index.append(train_index[randomIndex])\n",
    "        #print(randomIndex)\n",
    "        train_index.remove(randomIndex)\n",
    "    #train,test的index是抽取的数据集X的序号\n",
    "    x_disease_train = [x[item] for item in train_index]\n",
    "    x_admin_train = [x_admin[item] for item in train_index]\n",
    "    x_dissituation_train = [x_dissituation[item] for item in train_index]\n",
    "    x_treat_train = [x_treat[item]  for item in train_index]\n",
    "    x_disorder_train = [x_disorder[item] for item in train_index]\n",
    "    \n",
    "    x_disease_test = [x[item] for item in test_index]\n",
    "    x_admin_test = [x_admin[item] for item in test_index]\n",
    "    x_dissituation_test = [x_dissituation[item] for item in test_index]\n",
    "    x_treat_test = [x_treat[item]  for item in test_index]\n",
    "    x_disorder_test = [x_disorder[item] for item in test_index]\n",
    "    \n",
    "    y_train = [y[item] for item in train_index]\n",
    "    y_test = [y[item] for item in test_index]\n",
    "\n",
    "    return x_disease_train, x_admin_train,x_dissituation_train,x_treat_train,x_disorder_train, x_disease_test,x_admin_test,x_dissituation_test,x_treat_test,x_disorder_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size= 46242 test size= 10174\n",
      "sum= 56416\n"
     ]
    }
   ],
   "source": [
    "#1.load all datasets  2.do split on each first type datasets 3.merge to a final train and test sets 4.word to vector 5.do rf train and test\n",
    "#1.load all dataset pd_dia_dis\n",
    "def classifyDatasetsTFAll(pd_dia_dis,admin,dissituation,treat,disorder, rate):\n",
    "    x_disease_trainAll = list()\n",
    "    x_admin_trainAll = list()\n",
    "    x_dissituation_trainAll = list()\n",
    "    x_treat_trainAll = list()\n",
    "    x_disorder_trainAll = list()\n",
    "    \n",
    "    x_disease_testAll = list()\n",
    "    x_admin_testAll = list()\n",
    "    x_dissituation_testAll = list()\n",
    "    x_treat_testAll = list()\n",
    "    x_disorder_testAll = list()\n",
    "    \n",
    "    y_trainAll = list()\n",
    "    y_testAll = list()\n",
    "    \n",
    "    for item in firstCode2IndexDict.keys():\n",
    "        #2.do split oon each first type, disease and admission_situation\n",
    "        #print(\"item=\", item,firstCode2IndexDict[item])\n",
    "        pd_tmp = pd_dia_dis[pd_dia_dis[\"FirstCode\"]==item]\n",
    "        x_disease = pd_tmp['disease'].tolist()\n",
    "        #print(\"dis num=\",len(x_disease))\n",
    "        x_admin = pd_tmp[admin].tolist()\n",
    "        x_dissituation = pd_tmp[dissituation].tolist()\n",
    "        x_treat = pd_tmp[treat].tolist()\n",
    "        x_disorder = pd_tmp[disorder].tolist()\n",
    "\n",
    "        #x_admin = pd_tmp[\"admission_situationKey\"].tolist()\n",
    "        label = firstCode2IndexDict[item]\n",
    "        nums = len(x_disease)\n",
    "        if nums==0:\n",
    "            continue\n",
    "        y = [label]*nums\n",
    "        x_disease_train, x_admin_train,x_dissituation_train,x_treat_train,x_disorder_train, x_disease_test,\\\n",
    "            x_admin_test,x_dissituation_test,x_treat_test,x_disorder_test, y_train, y_test=doDatasetSplitAll(\n",
    "            x_disease,x_admin, x_dissituation,x_treat,x_disorder,y, rate)\n",
    "        #3.merge \n",
    "        x_disease_trainAll.extend(x_disease_train)\n",
    "        x_admin_trainAll.extend(x_admin_train)\n",
    "        x_dissituation_trainAll.extend(x_dissituation_train)\n",
    "        x_treat_trainAll.extend(x_treat_train)\n",
    "        x_disorder_trainAll.extend(x_disorder_train)\n",
    "        \n",
    "        x_disease_testAll.extend(x_disease_test)\n",
    "        x_admin_testAll.extend(x_admin_test)\n",
    "        x_dissituation_testAll.extend(x_dissituation_test)\n",
    "        x_treat_testAll.extend(x_treat_test)\n",
    "        x_disorder_testAll.extend(x_disorder_test)\n",
    "        \n",
    "        y_trainAll.extend(y_train)\n",
    "        y_testAll.extend(y_test)\n",
    "    print(\"train size=\", len(y_trainAll), \"test size=\", len(y_testAll))\n",
    "    print(\"sum=\",len(y_trainAll)+len(y_testAll))\n",
    "        \n",
    "    return x_disease_trainAll, x_admin_trainAll,x_dissituation_trainAll,x_treat_trainAll,x_disorder_trainAll,\\\n",
    "        x_disease_testAll,x_admin_testAll,x_dissituation_testAll, x_treat_testAll,x_disorder_testAll,y_trainAll, y_testAll\n",
    "rate = 0.2\n",
    "admin = \"admission_situationKey\"\n",
    "dissituation = \"discharge_situationKey\"\n",
    "treat = \"treat_processKey\"\n",
    "disorder = \"discharge_orderKey\"\n",
    "x_disease_trainAll, x_admin_trainAll,x_dissituation_trainAll,x_treat_trainAll,x_disorder_trainAll,\\\n",
    "    x_disease_testAll,x_admin_testAll,x_dissituation_testAll, x_treat_testAll,x_disorder_testAll,y_trainAll, y_testAll= classifyDatasetsTFAll( \\\n",
    "    pd_dia_dis,admin,dissituation,treat,disorder, rate\\\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_disease_train: 46242\n",
      "x_admin_train: 46242\n",
      "x_dissituation_train: 46242\n",
      "x_treat_train: 46242\n",
      "x_disorder_train: 46242\n"
     ]
    }
   ],
   "source": [
    "print(\"x_disease_train:\",len(x_disease_trainAll))\n",
    "print(\"x_admin_train:\",len(x_admin_trainAll))\n",
    "print(\"x_dissituation_train:\", len(x_dissituation_trainAll))\n",
    "print(\"x_treat_train:\", len(x_treat_trainAll))\n",
    "print(\"x_disorder_train:\", len(x_disorder_trainAll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keywordpad(inStr,maxlen,dtype='int32',value=0.):\n",
    "    inStrArr = str(inStr).strip().split(\" \")\n",
    "    trunc = inStrArr[:maxlen]\n",
    "    x = [\"0\" for i in range(maxlen)]\n",
    "    x[:len(trunc)] = trunc\n",
    "    return \" \".join(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构造CNN四个字段的数据集合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def doPrepareCNNAll(x_disease_trainAll, x_admin_trainAll,x_dissituation_trainAll,x_treat_trainAll,x_disorder_trainAll, y_trainAll, filePath):\n",
    "    f = open(filePath+\".feature\", \"w\")\n",
    "    f_label =open(filePath+\".label\" ,\"w\")\n",
    "    for i in range (len(x_disease_trainAll)):\n",
    "        dis = x_disease_trainAll[i]\n",
    "        adm = x_admin_trainAll[i]\n",
    "        dissituation = x_dissituation_trainAll[i]\n",
    "        treat = x_treat_trainAll[i]\n",
    "        disorder = x_disorder_trainAll[i]\n",
    "        y_train = y_trainAll[i]\n",
    "        \n",
    "        y_trainStr = (\"%s \" %(y_train))\n",
    "        #featureStr = (\"%s%s\" %(str(dis)+\" \" + str(adm) + \" __label__\", y_trainStr))\n",
    "                               \n",
    "        featureStr = (\"%s\" %(str(dis)+\" \" + str( keywordpad(adm,20))+\" \"+str(keywordpad(dissituation,20))+\" \"+str(keywordpad(treat,20))+\" \"+str(keywordpad(disorder,20)) ))\n",
    "\n",
    "        labelStr = (\"%s\" %(y_trainStr))\n",
    "        f.write(str(featureStr)+\"\\n\")\n",
    "        f_label.write(labelStr+\"\\n\")\n",
    "    f.flush()\n",
    "    f.close()\n",
    "\n",
    "filePath = \"cnnModel/datasets/trainall\"\n",
    "doPrepareCNNAll(x_disease_trainAll, x_admin_trainAll,x_dissituation_trainAll,x_treat_trainAll,x_disorder_trainAll, y_trainAll, filePath )\n",
    "filePathtest = \"cnnModel/datasets/testall\"\n",
    "doPrepareCNNAll(x_disease_testAll,x_admin_testAll,x_dissituation_testAll,x_treat_testAll,x_disorder_testAll,y_testAll, filePathtest )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
